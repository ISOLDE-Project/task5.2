{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18 Inference example  \n",
    "\n",
    "For the first time usage, make sure you have run all the cells in [Get-ResNet-18_Model.ipynb](./Get-ResNet-18_Model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.resnet18()\n",
    "state_dict = torch.load('zoo/resnet18_model.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "file_path = 'zoo/imagenet-simple-labels.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    labels = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on an example image\n",
    "image_url = 'https://www.hartz.com/wp-content/uploads/2022/04/small-dog-owners-1.jpg'  # Provide an image URL\n",
    "# Download the image\n",
    "response = requests.get(image_url,verify=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(BytesIO(response.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_data = preprocess(img)\n",
    "input_data = input_data.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_data)\n",
    "\n",
    "# Post-process the results\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "predicted_class = torch.argmax(probabilities).item()\n",
    "\n",
    "\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = labels[predicted_class]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "print(f\"Probability: {probabilities[predicted_class]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_data.numpy()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X\",X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ! Channel first !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=np.load('X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test image for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#plt.figure()\n",
    "axes[0].imshow(X[0][0], cmap='Reds')\n",
    "axes[1].imshow(X[0][1], cmap='Greens')\n",
    "axes[2].imshow(X[0][2], cmap='Blues')\n",
    "#plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transposed = np.transpose(X[0], (1, 2, 0))\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(X_transposed)\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import onnx\n",
    "import netron\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_model(model_file_name,itf='10.217.184.110',port=8098):\n",
    "    netron.start(file=model_file_name,address=(itf,port))\n",
    "    return port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path=pathlib.Path(\"onnx/resnet18.onnx\")\n",
    "#input_path=pathlib.Path(\"onnx/submodel_46_48.onnx\")\n",
    "onnx_model = onnx.load(input_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opset(model):\n",
    "    fields =model.opset_import\n",
    "    field=  fields[0]\n",
    "    return field.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{get_opset(onnx_model)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port=show_model(\"./\"+str(input_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = onnx_model.graph\n",
    "input_name=graph.node[0].input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=[]\n",
    "for node in graph.node:\n",
    "    outputs.append(node.output[0])\n",
    "print(outputs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs=['/Flatten_output_0','191']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import google.protobuf.internal.containers \n",
    "google.protobuf.internal.containers.RepeatedScalarFieldContainer: out =outputs[0]\n",
    "type(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx.helper as helper\n",
    "for tensor_name in outputs:\n",
    "    intermediate_tensor_name = tensor_name\n",
    "    intermediate_layer_value_info = helper.ValueInfoProto()\n",
    "    intermediate_layer_value_info.name = intermediate_tensor_name\n",
    "    onnx_model.graph.output.extend([intermediate_layer_value_info])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString(),\n",
    "                                        providers=[\"CPUExecutionProvider\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "onnx_pred = sess.run(outputs, {input_name: X})\n",
    "#X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=None):\n",
    "    x = x - x.max(axis=axis, keepdims=True)\n",
    "    y = np.exp(x)\n",
    "    return y / y.sum(axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_idx=len(onnx_pred)-1\n",
    "graph_output=onnx_pred[last_idx]\n",
    "probabilities = softmax(graph_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxMax = np.argmax(graph_output)\n",
    "print(f\"Predicted class is '{idxMax}' with probability {probabilities[idxMax]}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=onnx_pred[0]\n",
    "np.save('X1',X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_c_array(var):\n",
    "    theShape=var.shape;\n",
    "    theRank=len(theShape)\n",
    "    txt =f\"{{\\n\"\n",
    "    #print(f\"the rank={theRank}, the shape={theShape}\")\n",
    "    if theRank == 1:\n",
    "        \n",
    "        txt =f\"{{ {var[0]}\"\n",
    "        for i in range(1,theShape[0]):\n",
    "             txt+=f\", {var[i]}\"\n",
    "        txt+=f' }}'     \n",
    "        #print(txt)\n",
    "        return txt\n",
    "        \n",
    "    for i in range(0,theShape[0]):\n",
    "        #print(f\"-recursive {i},{var.shape}\")\n",
    "        a = var[i] \n",
    "        txt+=export_to_c_array(a)\n",
    "        #txt+=f\"}}\\n\"\n",
    "        if i<theShape[0]-1:\n",
    "            txt+=',\\n'\n",
    "        else:\n",
    "            txt+=' \\n'    \n",
    "    return txt+f\"}}\"\n",
    "\n",
    "def export_to_c(file_name,varname,var):\n",
    "    txt = f\"float {varname}\"\n",
    "    for k in var.shape:\n",
    "        txt+=f\"[{k}]\"\n",
    "    txt+= ' = \\n'\n",
    "    values =export_to_c_array(var)\n",
    "    txt+= f\"{values};\"\n",
    "    cpp_file = open(file_name, \"w\")\n",
    "    cpp_file.write(txt)\n",
    "    cpp_file.close()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo=export_to_c('data.cpp','input',X)\n",
    "print(echo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save intermediary outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =1\n",
    "for pred in onnx_pred:\n",
    "    fname=f\"y_{i}_ref\"\n",
    "    np.save(fname,pred)\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
    "\n",
    "pydot_graph = GetPydotGraph(\n",
    "    onnx_model.graph,  # model_onnx is a ModelProto instance\n",
    "    name=onnx_model.graph.name,\n",
    "    rankdir=\"TP\",\n",
    "    node_producer=GetOpNodeProducer(\"docstring\"))\n",
    "pydot_graph.write_dot(\"graph.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_operators_report(onnx_model):\n",
    "    operators_list = []\n",
    "    operator_idx={}\n",
    "    operators_occurence_dict = dict()\n",
    "\n",
    "    idx =0\n",
    "    for operator in onnx_model.graph.node:\n",
    "        operator_idx.update({idx: [operator.op_type,operator.name,operator.output]})\n",
    "        idx+=1\n",
    "        operators_list.append(operator.op_type)\n",
    "        if operator.op_type in operators_occurence_dict:\n",
    "            operators_occurence_dict[operator.op_type] += 1\n",
    "        else:\n",
    "            operators_occurence_dict[operator.op_type] = 1\n",
    "\n",
    "    sorted_operators_occurence_dict = dict(sorted(operators_occurence_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    return operators_list, sorted_operators_occurence_dict,operator_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_list,sorted_op_list,op_id =generate_operators_report(onnx_model=onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_start=0\n",
    "idx_end=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ onnx_model.graph.node[idx_start].input[0]]\n",
    "outputs = onnx_model.graph.node[idx_end].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F\"{inputs}==>{outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model=str(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=f'onnx/submodel_{idx_start}_{idx_end}.onnx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.utils.extract_model(old_model, new_model, inputs,outputs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_new_model = onnx.load(new_model)\n",
    "onnx.checker.check_model(onnx_new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port=show_model(\"./\"+str(new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "sess = rt.InferenceSession(onnx_new_model.SerializeToString(),\n",
    "                                        providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "#X = np.load('X1.npy')\n",
    "#X = np.load('X2.npy')\n",
    "input_name=onnx_new_model.graph.node[0].input[0]\n",
    "onnx_pred = sess.run(outputs, {input_name: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_idx=len(onnx_pred)-1\n",
    "graph_output=onnx_pred[last_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = softmax(graph_output[0])\n",
    "idxMax = np.argmax(graph_output)\n",
    "print(f\"Predicted class is '{idxMax}' with probability {probabilities[idxMax]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo=export_to_c('data2.cpp','input',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"Y_{idx_start}_{idx_end}\",graph_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myTensor=np.array([\n",
    "[\n",
    "[\t[1.,2,3],\n",
    "    [4,5,7],\n",
    "    [8,9,10],\n",
    "    [81,91,11]\n",
    "],\n",
    "[\t[10.,20,30],\n",
    "    [40,50,70],\n",
    "    [80,90,10],\n",
    "    [801,901,101]\n",
    "]\n",
    "]\n",
    "],dtype= np.float32)\n",
    "\n",
    "print(export_to_c_array(myTensor))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86f0ff04287dd0dcf64a58fd168df5e181c72c882d1186882ca2aeb786c2f25b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
